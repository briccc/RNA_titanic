{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder # convertir categorias a num\n",
    "\n",
    "#añadir random forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "df = pd.read_csv('train.csv')   \n",
    "# print(df.head())\n",
    "# print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpieza y preparacion de datos\n",
    "\n",
    "# eliminar columnas que no tienen relevancia para el modelo\n",
    "df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# rellenar en la columna edad con la mediana (edad típica) para no perder data\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "# rellenar en la columna embarked con la moda (valor mas frecuente) para no perder data\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['Sex'] = label_encoder.fit_transform(df['Sex'])       # hombre = 1, mujer = 0\n",
    "df['Embarked'] = label_encoder.fit_transform(df['Embarked']) # puerto de embarque = 0, puerto de embarque = 1, puerto de embarque = 2\n",
    "\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separar las x de nuestra y (saber si sobrevivio o no)\n",
    "X = df.drop('Survived', axis=1)  # drop survived\n",
    "y = df['Survived']               # columna a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividir en entrenamiento y prueba 80/20\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# dividimos el conj de entrenamiento en entrenamiento y validación 75/25 de ese 80\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizar o escalado media ≈ 0 desviación estándar ≈ 1\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# ajustar solo con data de entrenamiento y transformar \n",
    "X_train = scaler.fit_transform(X_train)  # ademas de transformar aprende\n",
    "X_val = scaler.transform(X_val) #validacion\n",
    "X_test = scaler.transform(X_test) #prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 1: 1 capa oculta con 100 neuronas, 1000 iteraciones, solver: sgd, random state 42\n",
      "\n",
      "Accuracy en validación: 0.8033707865168539\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       112\n",
      "           1       0.75      0.71      0.73        66\n",
      "\n",
      "    accuracy                           0.80       178\n",
      "   macro avg       0.79      0.78      0.79       178\n",
      "weighted avg       0.80      0.80      0.80       178\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      " [[96 16]\n",
      " [19 47]]\n"
     ]
    }
   ],
   "source": [
    "# modelo 1: 1 capa oculta con 100 neuronas, 1000 iteraciones, solver: sgd, random state 42\n",
    "\n",
    "# modelo con hiperparametros iniciales\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, solver='sgd', random_state=42) #creacion\n",
    "mlp.fit(X_train, y_train) #entrenamiento \n",
    "\n",
    "# validacion\n",
    "y_pred_val = mlp.predict(X_val)\n",
    "\n",
    "# evaluacion de nuestra data de validacion\n",
    "print(\"Modelo 1: 1 capa oculta con 100 neuronas, 1000 iteraciones, solver: sgd, random state 42\")\n",
    "print(\"\\nAccuracy en validación:\", accuracy_score(y_val, y_pred_val))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_val, y_pred_val))\n",
    "cm = confusion_matrix(y_val, y_pred_val)\n",
    "print(\"\\nMatriz de confusión:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 2: 2 capas ocultas, solver 'adam', max_iter 2000, learning_rate_init 0.001, random state 42\n",
      "\n",
      "Accuracy en validación: 0.8146067415730337\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85       112\n",
      "           1       0.76      0.73      0.74        66\n",
      "\n",
      "    accuracy                           0.81       178\n",
      "   macro avg       0.80      0.80      0.80       178\n",
      "weighted avg       0.81      0.81      0.81       178\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      " [[97 15]\n",
      " [18 48]]\n"
     ]
    }
   ],
   "source": [
    "# modelo 2: 2 capas ocultas, solver 'adam', max_iter 2000, learning_rate_init 0.001, random state 42\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=2000, solver='adam', learning_rate_init=0.001, random_state=42)\n",
    "mlp2.fit(X_train, y_train)  # entrenamiento\n",
    "\n",
    "# validacion\n",
    "y_pred_val2 = mlp2.predict(X_val)\n",
    "\n",
    "# evaluacion de nuestra data de validacion\n",
    "print(\"Modelo 2: 2 capas ocultas, solver 'adam', max_iter 2000, learning_rate_init 0.001, random state 42\")\n",
    "print(\"\\nAccuracy en validación:\", accuracy_score(y_val, y_pred_val2))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_val, y_pred_val2))\n",
    "print(\"\\nMatriz de confusión:\\n\", confusion_matrix(y_val, y_pred_val2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 3: 3 capas ocultas (100,50,25), solver 'adam', max_iter 3000, learning_rate_init 0.0005,\n",
      "alpha 0.1, random state 42\n",
      "\n",
      "Accuracy en validación: 0.797752808988764\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       112\n",
      "           1       0.73      0.71      0.72        66\n",
      "\n",
      "    accuracy                           0.80       178\n",
      "   macro avg       0.78      0.78      0.78       178\n",
      "weighted avg       0.80      0.80      0.80       178\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      " [[95 17]\n",
      " [19 47]]\n"
     ]
    }
   ],
   "source": [
    "# modelo 3: 3 capas ocultas, solver 'adam', max_iter 3000, learning_rate_init 0.0005, alpha 0.0001, random state 42\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(100, 50, 25), \n",
    "                     max_iter=1000, \n",
    "                     solver='adam', \n",
    "                     learning_rate_init=0.0005, \n",
    "                     alpha=0.1, # regularizacion de pesos, penaliza pesos grandes\n",
    "                     random_state=42)\n",
    "mlp3.fit(X_train, y_train)  # entrenamiento\n",
    "\n",
    "# validacion\n",
    "y_pred_val3 = mlp3.predict(X_val)\n",
    "\n",
    "# evaluacion de nuestra data de validacion\n",
    "print(\"Modelo 3: 3 capas ocultas (100,50,25), solver 'adam', max_iter 3000, learning_rate_init 0.0005,\\nalpha 0.1, random state 42\")\n",
    "print(\"\\nAccuracy en validación:\", accuracy_score(y_val, y_pred_val3))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_val, y_pred_val3))\n",
    "print(\"\\nMatriz de confusión:\\n\", confusion_matrix(y_val, y_pred_val3))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 4: 1 capa oculta, solver 'lbfgs', max_iter 1000, random_state 42\n",
      "Accuracy en validación: 0.7584269662921348\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80       112\n",
      "           1       0.66      0.73      0.69        66\n",
      "\n",
      "    accuracy                           0.76       178\n",
      "   macro avg       0.74      0.75      0.75       178\n",
      "weighted avg       0.77      0.76      0.76       178\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      " [[87 25]\n",
      " [18 48]]\n"
     ]
    }
   ],
   "source": [
    "# modelo 4: 1 capa oculta, solver 'lbfgs', max_iter 1000, random state 42\n",
    "mlp4 = MLPClassifier(hidden_layer_sizes=(100,), solver='lbfgs', max_iter=2000, random_state=42)\n",
    "mlp4.fit(X_train, y_train)\n",
    "\n",
    "# validacion\n",
    "y_pred_val4 = mlp4.predict(X_val)\n",
    "\n",
    "# evaluacion de nuestra data de validacion\n",
    "print(\"Modelo 4: 1 capa oculta, solver 'lbfgs', max_iter 1000, random_state 42\")\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_val, y_pred_val4))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_val, y_pred_val4))\n",
    "print(\"\\nMatriz de confusión:\\n\", confusion_matrix(y_val, y_pred_val4))\n",
    "\n",
    "# lbfgs NO loss_curve_ porque no guarda el historial de la función de pérdida durante el entrenamiento como los otros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros encontrados: {'alpha': 0.0001, 'hidden_layer_sizes': (150, 75), 'learning_rate_init': 0.0001}\n",
      "Mejor accuracy en validación cruzada: 0.818462352318815\n",
      "\n",
      "Accuracy en validación: 0.8314606741573034\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       112\n",
      "           1       0.80      0.73      0.76        66\n",
      "\n",
      "    accuracy                           0.83       178\n",
      "   macro avg       0.82      0.81      0.82       178\n",
      "weighted avg       0.83      0.83      0.83       178\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      " [[100  12]\n",
      " [ 18  48]]\n"
     ]
    }
   ],
   "source": [
    "#automatizar busqueda de la mejor combinacion de hiperparametros PARA EL MODELO 2\n",
    "#tuning de hiperparametros\n",
    "\n",
    "# grilla de hiperparametros \n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100, 50), (100, 50, 25), (50, 25), (100,), (150, 75)],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate_init': [0.001, 0.0005, 0.0001]\n",
    "}\n",
    "\n",
    "# modelo 2\n",
    "mlp_base = MLPClassifier(max_iter=2000, solver='adam', random_state=42)\n",
    "\n",
    "# dreacion del GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=mlp_base, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n",
    "print(\"Mejor accuracy en validación cruzada:\", grid_search.best_score_)\n",
    "\n",
    "# evaluacion sobre el conjunto de validacion\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_val_best = best_model.predict(X_val)\n",
    "\n",
    "print(\"\\nAccuracy en validación:\", accuracy_score(y_val, y_pred_val_best))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_val, y_pred_val_best))\n",
    "print(\"\\nMatriz de confusión:\\n\", confusion_matrix(y_val, y_pred_val_best))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación final con el conjunto de prueba:\n",
      "Accuracy: 0.8044692737430168\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       105\n",
      "           1       0.79      0.72      0.75        74\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.79      0.80       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      " [[91 14]\n",
      " [21 53]]\n"
     ]
    }
   ],
   "source": [
    "# evaluacion final con el conjunto de prueba\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Evaluación final con el conjunto de prueba:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_pred_test))\n",
    "print(\"\\nMatriz de confusión:\\n\", confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Validación\n",
      "Accuracy: 0.8089887640449438\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       112\n",
      "           1       0.75      0.73      0.74        66\n",
      "\n",
      "    accuracy                           0.81       178\n",
      "   macro avg       0.80      0.79      0.79       178\n",
      "weighted avg       0.81      0.81      0.81       178\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      " [[96 16]\n",
      " [18 48]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val_rf = rf.predict(X_val)\n",
    "\n",
    "print(\"Random Forest - Validación\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_val_rf))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_val, y_pred_val_rf))\n",
    "print(\"\\nMatriz de confusión:\\n\", confusion_matrix(y_val, y_pred_val_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Evaluación final con el conjunto de prueba\n",
      "Accuracy: 0.8268156424581006\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       105\n",
      "           1       0.81      0.76      0.78        74\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.82      0.82      0.82       179\n",
      "weighted avg       0.83      0.83      0.83       179\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      " [[92 13]\n",
      " [18 56]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_test_rf = rf.predict(X_test)\n",
    "print(\"Random Forest - Evaluación final con el conjunto de prueba\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test_rf))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_pred_test_rf))\n",
    "print(\"\\nMatriz de confusión:\\n\", confusion_matrix(y_test, y_pred_test_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
